"""Alpaca Dataset Machine Translated"""

import json
import datasets

_CITATION = """\
@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {https://github.com/tatsu-lab/stanford_alpaca},
}
"""

_DESCRIPTION = """\
Alpaca is a dataset of 52,000 instructions and demonstrations generated by OpenAI's text-davinci-003 engine. This instruction data can be used to conduct instruction-tuning for language models and make the language model follow instruction better. This dataset also includes machine-translated data for 5 languages: Portuguese, Spanish, Catalan, Basque and Galician.
"""

_LANG = ["en", "pt", "es", "ca", "eu", "gl", "at"]
_URL_FORMAT = "../data/alpaca_data_cleaned_{lang}.json"

PROMPTS = {
    "en": {
        "prompt_input": (
            "Below is an instruction that describes a task, paired with an input that provides further context. "
            "Write a response that appropriately completes the request.\n\n"
            "### Instruction:\n{instruction}\n\n### Input:\n{input}\n\n### Response:\n"
        ),
        "prompt_no_input": (
            "Below is an instruction that describes a task. "
            "Write a response that appropriately completes the request.\n\n"
            "### Instruction:\n{instruction}\n\n### Response:\n"
        ),
    },
    "pt": {
        "prompt_input": (
            "Abaixo está uma instrução que descreve uma tarefa, juntamente com uma entrada que fornece mais contexto. "
            "Escreva uma resposta que complete adequadamente o pedido.\n\n"
            "### Instrução:\n{instruction}\n\n### Entrada:\n{input}\n\n### Resposta:\n"
        ),
        "prompt_no_input": (
            "Abaixo está uma instrução que descreve uma tarefa. "
            "Escreva uma resposta que complete adequadamente o pedido.\n\n"
            "### Instrução:\n{instruction}\n\n### Resposta:\n"
        ),
    },
    "es": {
        "prompt_input": (
            "A continuación se muestra una instrucción que describe una tarea, junto con una entrada que proporciona más contexto. "
            "Escribe una respuesta que complete adecuadamente la petición.\n\n"
            "### Instrucción:\n{instruction}\n\n### Entrada:\n{input}\n\n### Respuesta:\n"
        ),
        "prompt_no_input": (
            "A continuación se muestra una instrucción que describe una tarea. "
            "Escribe una respuesta que complete adecuadamente la petición.\n\n"
            "### Instrucción:\n{instruction}\n\n### Respuesta:\n"
        ),
    },
    "ca": {
        "prompt_input": (
            "A continuació es mostra una instrucció que descriu una tasca, juntament amb una entrada que proporciona més context. "
            "Escriviu una resposta que completi adequadament la petició.\n\n"
            "### Instrucció:\n{instruction}\n\n### Entrada:\n{input}\n\n### Resposta:\n"
        ),
        "prompt_no_input": (
            "A continuació es mostra una instrucció que descriu una tasca. "
            "Escriviu una resposta que completi adequadament la petició.\n\n"
            "### Instrucció:\n{instruction}\n\n### Resposta:\n"
        ),
    },
    "eu": {
        "prompt_input": (
            "Azpian ataza bat deskribatzen duen instruzio bat dago, testuinguru gehiago ematen duen sarrera batekin batera. "
            "Idatzi eskaera behar bezala betetzen duen erantzuna.\n\n"
            "### Instrukzioa:\n{instruction}\n\n### Sarrera:\n{input}\n\n### Erantzuna:\n"
        ),
        "prompt_no_input": (
            "Azpian ataza bat deskribatzen duen instruzio bat dago. "
            "Idatzi eskaera behar bezala betetzen duen erantzuna.\n\n"
            "### Instrukzioa:\n{instruction}\n\n### Erantzuna:\n"
        ),
    },
    "gl": {
        "prompt_input": (
            "A seguinte é unha instrución que describe unha tarefa, xunto cunha entrada que proporciona máis contexto. "
            "Escriba unha resposta que complete correctamente a solicitude.\n\n"
            "### Instrución:\n{instruction}\n\n### Entrada:\n{input}\n\n### Resposta:\n"
        ),
        "prompt_no_input": (
            "A seguinte é unha instrución que describe unha tarefa. "
            "Escriba unha resposta que complete correctamente a solicitude.\n\n"
            "### Instrución:\n{instruction}\n\n### Resposta:\n"
        ),
    },
    "at": {
        "prompt_input": (
            "De siguío amuésase una instrucción que describe una xera, xuntu con una entrada qu'apurre más contestu. "
            "Escribe una respuesta que complete afechiscamente'l pidimientu.\n\n"
            "### Instrucción:\n{instruction}\n\n## Entrada:\n{input}\n\n### Respuesta:\n"
        ),
        "prompt_no_input": (
            "De siguío amuésase una instrucción que describe una xera. "
            "Escribe una respuesta que complete afechiscamente'l pidimientu.\n\n"
            "### Instrucción:\n{instrucción}\n\n## Respuesta:\n"
        ),
    },
}


def generate_prompt(data_point, lang):
    if data_point["input"]:
        return PROMPTS[lang]["prompt_input"].format_map(data_point)
    else:
        return PROMPTS[lang]["prompt_no_input"].format_map(data_point)


class AlpacaConfig(datasets.BuilderConfig):

    """BuilderConfig for Alpaca"""

    def __init__(self, lang, **kwargs):
        """
        Args:
            lang: string, language for the input text
            **kwargs: keyword arguments forwarded to super.
        """
        super(AlpacaConfig, self).__init__(
            version=datasets.Version("1.0.0", ""), **kwargs
        )
        self.lang = lang


class Alpaca(datasets.GeneratorBasedBuilder):
    """Alpaca: Intruction Tuning Dataset."""

    VERSION = datasets.Version("1.0.0")

    BUILDER_CONFIGS = [
        AlpacaConfig(
            name=lang,
            lang=lang,
            description=f"Alpaca Dataset in {lang} language.",
        )
        for lang in _LANG
    ]

    def _info(self):
        return datasets.DatasetInfo(
            # This is the description that will appear on the datasets page.
            description=_DESCRIPTION,
            features=datasets.Features(
                {
                    "instruction": datasets.Value("string"),
                    "input": datasets.Value("string"),
                    "output": datasets.Value("string"),
                    "prompt": datasets.Value("string"),
                }
            ),
            # Homepage of the dataset for documentation
            homepage="https://crfm.stanford.edu/2023/03/13/alpaca.html",
            citation=_CITATION,
        )

    def _split_generators(self, dl_manager):
        """Returns SplitGenerators."""
        lang = self.config.lang

        if lang in _LANG:
            filepaths = dl_manager.download_and_extract(
                {
                    "train": _URL_FORMAT.format(lang=lang),
                }
            )

        return [
            datasets.SplitGenerator(
                name=split,
                # These kwargs will be passed to _generate_examples
                gen_kwargs={"filepath": path},
            )
            for split, path in filepaths.items()
        ]

    def _generate_examples(self, filepath):
        """Yields examples."""
        lang = self.config.lang
        with open(filepath, encoding="utf-8") as f:
            alpaca = json.load(f)
            for i, example in enumerate(alpaca):
                yield i, {
                    "instruction": example["instruction"],
                    "input": example["input"],
                    "output": example["output"],
                    "prompt": generate_prompt(example, lang),
                }
